{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_features = 4\n",
    "m_examples = 47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have $X$, $m$ examples. Each example (each row) has $n$ features. Thus we have:\n",
    "$$ \n",
    "\\left[\\begin{array}{cccc}\n",
    "x^{(1)}_{1} & x^{(1)}_{2} & \\ldots & x^{(1)}_{n} \\\\\n",
    "x^{(2)}_{1} & x^{(2)}_{2} & \\ldots & x^{(2)}_{n} \\\\\n",
    "& & \\vdots \\\\\n",
    "x^{(m)}_{1} & x^{(m)}_{2} & \\ldots & x^{(m)}_{n}\n",
    "\\end{array}\\right] \\times\n",
    "\\left[\\begin{array}{c}\n",
    "w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n\n",
    "\\end{array}\\right] + b =\n",
    "\\left[\\begin{array}{c}\n",
    "y_1 \\\\ y_2 \\\\ \\vdots \\\\ v_n\n",
    "\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [5.48, 90.52, 48.29, 38.47]\n",
      "b = -9.33\n"
     ]
    }
   ],
   "source": [
    "# The input examples. The i-th row contains the i-th example. \n",
    "X_true = np.random.rand(m_examples, n_features)\n",
    "\n",
    "# This is what we wish linear regression to learn.\n",
    "w_true = np.random.rand(n_features, 1) * 100.0\n",
    "# The constant\n",
    "b_true = np.random.rand(1) * 100.0 - 50.0\n",
    "\n",
    "print \"w = [%s]\" % ', '.join(['%.2f' % x for x in w_true])\n",
    "print \"b = %.2f\" % b_true[0]\n",
    "\n",
    "# Noise\n",
    "noise = np.random.rand(m_examples, 1) / 100.0\n",
    "\n",
    "# These are our labeled \"results\". \n",
    "y_true = (np.matmul(X_true, w_true) + b_true) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Placeholder that is fed input data.\n",
    "X_in = tf.placeholder(tf.float32, [None, n_features], \"X_in\")\n",
    "\n",
    "# The model: we assume y = X_in * w + b\n",
    "w = tf.Variable(tf.random_normal((n_features, 1)), name=\"w\")\n",
    "b = tf.Variable(tf.constant(0.1, shape=[]), name=\"b\")\n",
    "h = tf.add(tf.matmul(X_in, w), b, name=\"h\")\n",
    "\n",
    "# Placeholder that is fed observed results.\n",
    "y_in = tf.placeholder(tf.float32, [None, 1], \"y_in\")\n",
    "\n",
    "# The loss function: we are minimizing square root of mean \n",
    "loss_op = tf.reduce_mean(tf.square(tf.subtract(y_in, h)), name=\"loss\")\n",
    "train_op = tf.train.GradientDescentOptimizer(0.3).minimize(loss_op)\n",
    "\n",
    "# The total number of batches.\n",
    "batch_count = 200\n",
    "\n",
    "# Steps per batch\n",
    "steps_per_batch = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Clear any existing logs\n",
    "    shutil.rmtree(\"/tmp/linreg_log\", True)\n",
    "    writer = tf.summary.FileWriter(\"/tmp/linreg_log\", \n",
    "                                   sess.graph)\n",
    "    loss_summ = tf.summary.scalar(\"loss\", loss_op)\n",
    "    for batch in range(batch_count):\n",
    "        for step in range(steps_per_batch):\n",
    "            sess.run(train_op, \n",
    "                     feed_dict={X_in: X_true, y_in: y_true})\n",
    "        writer.add_summary(\n",
    "          sess.run(loss_summ, \n",
    "                   feed_dict={X_in: X_true, y_in: y_true}), \n",
    "          batch * steps_per_batch)\n",
    "    w_computed = sess.run(w)\n",
    "    b_computed = sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w computed [5.48375, 90.52216, 48.28834, 38.46674]\n",
      "w actual   [5.48446, 90.52165, 48.28952, 38.46534]\n",
      "b computed -9.326\n",
      "b actual  -9.331\n"
     ]
    }
   ],
   "source": [
    "print \"w computed [%s]\" % ', '.join(['%.5f' % x for x in w_computed.flatten()])\n",
    "print \"w actual   [%s]\" % ', '.join(['%.5f' % x for x in w_true.flatten()])\n",
    "print \"b computed %.3f\" % b_computed\n",
    "print \"b actual  %.3f\" % b_true[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
